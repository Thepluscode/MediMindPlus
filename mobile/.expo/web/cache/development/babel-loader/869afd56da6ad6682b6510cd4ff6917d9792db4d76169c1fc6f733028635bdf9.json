{"ast":null,"code":"import _asyncToGenerator from \"@babel/runtime/helpers/asyncToGenerator\";\nimport _classCallCheck from \"@babel/runtime/helpers/classCallCheck\";\nimport _createClass from \"@babel/runtime/helpers/createClass\";\nvar EdgeAIProcessor = function () {\n  function EdgeAIProcessor() {\n    _classCallCheck(this, EdgeAIProcessor);\n    this.config = null;\n    this.models = new Map();\n    this.isInitialized = false;\n    this.inferenceQueue = [];\n  }\n  return _createClass(EdgeAIProcessor, [{\n    key: \"initialize\",\n    value: (function () {\n      var _initialize = _asyncToGenerator(function* (config) {\n        try {\n          console.log('üì± Initializing Edge AI Processor...');\n          this.config = config;\n          if (config.enableUncertaintyQuantification) {\n            yield this.initializeUncertaintyQuantification();\n          }\n          if (config.enableRealTimeInference) {\n            yield this.initializeRealTimeInference(config.targetLatency);\n          }\n          if (config.enableModelVersioning) {\n            yield this.initializeModelVersioning();\n          }\n          if (config.enableABTesting) {\n            yield this.initializeABTesting();\n          }\n          yield this.loadPretrainedModels();\n          this.isInitialized = true;\n          console.log('‚úÖ Edge AI Processor initialized successfully');\n        } catch (error) {\n          console.error('‚ùå Failed to initialize Edge AI Processor:', error);\n          throw error;\n        }\n      });\n      function initialize(_x) {\n        return _initialize.apply(this, arguments);\n      }\n      return initialize;\n    }())\n  }, {\n    key: \"initializeUncertaintyQuantification\",\n    value: (function () {\n      var _initializeUncertaintyQuantification = _asyncToGenerator(function* () {\n        console.log('üéØ Initializing Uncertainty Quantification...');\n        console.log('‚úÖ Uncertainty Quantification initialized');\n      });\n      function initializeUncertaintyQuantification() {\n        return _initializeUncertaintyQuantification.apply(this, arguments);\n      }\n      return initializeUncertaintyQuantification;\n    }())\n  }, {\n    key: \"initializeRealTimeInference\",\n    value: (function () {\n      var _initializeRealTimeInference = _asyncToGenerator(function* (targetLatency) {\n        console.log(`‚ö° Initializing Real-time Inference (target: ${targetLatency}ms)...`);\n        console.log('‚úÖ Real-time Inference initialized');\n      });\n      function initializeRealTimeInference(_x2) {\n        return _initializeRealTimeInference.apply(this, arguments);\n      }\n      return initializeRealTimeInference;\n    }())\n  }, {\n    key: \"initializeModelVersioning\",\n    value: (function () {\n      var _initializeModelVersioning = _asyncToGenerator(function* () {\n        console.log('üì¶ Initializing Model Versioning...');\n        console.log('‚úÖ Model Versioning initialized');\n      });\n      function initializeModelVersioning() {\n        return _initializeModelVersioning.apply(this, arguments);\n      }\n      return initializeModelVersioning;\n    }())\n  }, {\n    key: \"initializeABTesting\",\n    value: (function () {\n      var _initializeABTesting = _asyncToGenerator(function* () {\n        console.log('üß™ Initializing A/B Testing...');\n        console.log('‚úÖ A/B Testing initialized');\n      });\n      function initializeABTesting() {\n        return _initializeABTesting.apply(this, arguments);\n      }\n      return initializeABTesting;\n    }())\n  }, {\n    key: \"loadPretrainedModels\",\n    value: (function () {\n      var _loadPretrainedModels = _asyncToGenerator(function* () {\n        console.log('üîÑ Loading Pre-trained Models...');\n        var healthModel = {\n          id: 'health-risk-predictor',\n          version: '1.0.0',\n          type: 'tensorflow',\n          size: 5242880,\n          accuracy: 0.92,\n          latency: 50,\n          isLoaded: true\n        };\n        var vitalsModel = {\n          id: 'vitals-analyzer',\n          version: '1.0.0',\n          type: 'tensorflow',\n          size: 2097152,\n          accuracy: 0.95,\n          latency: 30,\n          isLoaded: true\n        };\n        var voiceModel = {\n          id: 'voice-biomarker',\n          version: '1.0.0',\n          type: 'pytorch',\n          size: 10485760,\n          accuracy: 0.88,\n          latency: 100,\n          isLoaded: true\n        };\n        this.models.set('health-risk', healthModel);\n        this.models.set('vitals', vitalsModel);\n        this.models.set('voice', voiceModel);\n        console.log(`‚úÖ Loaded ${this.models.size} pre-trained models`);\n      });\n      function loadPretrainedModels() {\n        return _loadPretrainedModels.apply(this, arguments);\n      }\n      return loadPretrainedModels;\n    }())\n  }, {\n    key: \"performInference\",\n    value: (function () {\n      var _performInference = _asyncToGenerator(function* (modelId, input) {\n        var _this$config, _this$config2;\n        if (!this.isInitialized) {\n          throw new Error('Edge AI Processor not initialized');\n        }\n        var startTime = Date.now();\n        var model = this.models.get(modelId);\n        if (!model) {\n          throw new Error(`Model ${modelId} not found`);\n        }\n        var output = yield this.runModelInference(model, input);\n        var endTime = Date.now();\n        var latency = endTime - startTime;\n        var uncertainty = 0;\n        if ((_this$config = this.config) != null && _this$config.enableUncertaintyQuantification) {\n          uncertainty = yield this.calculateUncertainty(model, input, output);\n        }\n        var inference = {\n          modelId: model.id,\n          input: input,\n          output: output,\n          confidence: output.confidence || 0.9,\n          uncertainty: uncertainty,\n          latency: latency,\n          timestamp: new Date().toISOString()\n        };\n        if ((_this$config2 = this.config) != null && _this$config2.enableABTesting) {\n          yield this.logInferenceForABTesting(inference);\n        }\n        return inference;\n      });\n      function performInference(_x3, _x4) {\n        return _performInference.apply(this, arguments);\n      }\n      return performInference;\n    }())\n  }, {\n    key: \"runModelInference\",\n    value: (function () {\n      var _runModelInference = _asyncToGenerator(function* (model, input) {\n        switch (model.type) {\n          case 'tensorflow':\n            return this.runTensorFlowInference(model, input);\n          case 'pytorch':\n            return this.runPyTorchInference(model, input);\n          case 'onnx':\n            return this.runONNXInference(model, input);\n          default:\n            throw new Error(`Unsupported model type: ${model.type}`);\n        }\n      });\n      function runModelInference(_x5, _x6) {\n        return _runModelInference.apply(this, arguments);\n      }\n      return runModelInference;\n    }())\n  }, {\n    key: \"runTensorFlowInference\",\n    value: (function () {\n      var _runTensorFlowInference = _asyncToGenerator(function* (model, input) {\n        yield new Promise(function (resolve) {\n          return setTimeout(resolve, model.latency);\n        });\n        return {\n          prediction: Math.random(),\n          confidence: 0.85 + Math.random() * 0.15,\n          features: input\n        };\n      });\n      function runTensorFlowInference(_x7, _x8) {\n        return _runTensorFlowInference.apply(this, arguments);\n      }\n      return runTensorFlowInference;\n    }())\n  }, {\n    key: \"runPyTorchInference\",\n    value: (function () {\n      var _runPyTorchInference = _asyncToGenerator(function* (model, input) {\n        yield new Promise(function (resolve) {\n          return setTimeout(resolve, model.latency);\n        });\n        return {\n          prediction: Math.random(),\n          confidence: 0.80 + Math.random() * 0.20,\n          features: input\n        };\n      });\n      function runPyTorchInference(_x9, _x0) {\n        return _runPyTorchInference.apply(this, arguments);\n      }\n      return runPyTorchInference;\n    }())\n  }, {\n    key: \"runONNXInference\",\n    value: (function () {\n      var _runONNXInference = _asyncToGenerator(function* (model, input) {\n        yield new Promise(function (resolve) {\n          return setTimeout(resolve, model.latency);\n        });\n        return {\n          prediction: Math.random(),\n          confidence: 0.88 + Math.random() * 0.12,\n          features: input\n        };\n      });\n      function runONNXInference(_x1, _x10) {\n        return _runONNXInference.apply(this, arguments);\n      }\n      return runONNXInference;\n    }())\n  }, {\n    key: \"calculateUncertainty\",\n    value: (function () {\n      var _calculateUncertainty = _asyncToGenerator(function* (model, input, output) {\n        return Math.random() * 0.1;\n      });\n      function calculateUncertainty(_x11, _x12, _x13) {\n        return _calculateUncertainty.apply(this, arguments);\n      }\n      return calculateUncertainty;\n    }())\n  }, {\n    key: \"logInferenceForABTesting\",\n    value: (function () {\n      var _logInferenceForABTesting = _asyncToGenerator(function* (inference) {\n        console.log('Logging inference for A/B testing:', inference.modelId);\n      });\n      function logInferenceForABTesting(_x14) {\n        return _logInferenceForABTesting.apply(this, arguments);\n      }\n      return logInferenceForABTesting;\n    }())\n  }, {\n    key: \"getModelMetrics\",\n    value: function getModelMetrics(modelId) {\n      return this.models.get(modelId);\n    }\n  }, {\n    key: \"updateModel\",\n    value: (function () {\n      var _updateModel = _asyncToGenerator(function* (modelId, newVersion) {\n        var _this$config3;\n        if (!((_this$config3 = this.config) != null && _this$config3.enableModelVersioning)) {\n          throw new Error('Model versioning not enabled');\n        }\n        var model = this.models.get(modelId);\n        if (model) {\n          model.version = newVersion;\n          console.log(`Updated ${modelId} to version ${newVersion}`);\n        }\n      });\n      function updateModel(_x15, _x16) {\n        return _updateModel.apply(this, arguments);\n      }\n      return updateModel;\n    }())\n  }, {\n    key: \"isServiceInitialized\",\n    value: function isServiceInitialized() {\n      return this.isInitialized;\n    }\n  }, {\n    key: \"getLoadedModels\",\n    value: function getLoadedModels() {\n      return Array.from(this.models.values());\n    }\n  }], [{\n    key: \"initialize\",\n    value: function initialize(arg0) {\n      throw new Error('Method not implemented.');\n    }\n  }]);\n}();\nexport { EdgeAIProcessor };\nexport default new EdgeAIProcessor();","map":{"version":3,"names":["EdgeAIProcessor","_classCallCheck","config","models","Map","isInitialized","inferenceQueue","_createClass","key","value","_initialize","_asyncToGenerator","console","log","enableUncertaintyQuantification","initializeUncertaintyQuantification","enableRealTimeInference","initializeRealTimeInference","targetLatency","enableModelVersioning","initializeModelVersioning","enableABTesting","initializeABTesting","loadPretrainedModels","error","initialize","_x","apply","arguments","_initializeUncertaintyQuantification","_initializeRealTimeInference","_x2","_initializeModelVersioning","_initializeABTesting","_loadPretrainedModels","healthModel","id","version","type","size","accuracy","latency","isLoaded","vitalsModel","voiceModel","set","_performInference","modelId","input","_this$config","_this$config2","Error","startTime","Date","now","model","get","output","runModelInference","endTime","uncertainty","calculateUncertainty","inference","confidence","timestamp","toISOString","logInferenceForABTesting","performInference","_x3","_x4","_runModelInference","runTensorFlowInference","runPyTorchInference","runONNXInference","_x5","_x6","_runTensorFlowInference","Promise","resolve","setTimeout","prediction","Math","random","features","_x7","_x8","_runPyTorchInference","_x9","_x0","_runONNXInference","_x1","_x10","_calculateUncertainty","_x11","_x12","_x13","_logInferenceForABTesting","_x14","getModelMetrics","_updateModel","newVersion","_this$config3","updateModel","_x15","_x16","isServiceInitialized","getLoadedModels","Array","from","values","arg0"],"sources":["/Users/theophilusogieva/Desktop/MediMindPlus/MediMindPlus/frontend/src/services/iot/edgeAI.ts"],"sourcesContent":["/**\n * Edge AI Processor for Real-time Health Analysis\n * Implements on-device AI inference with uncertainty quantification\n */\n\nexport interface EdgeAIConfig {\n  enableUncertaintyQuantification: boolean;\n  enableRealTimeInference: boolean;\n  targetLatency: number; // milliseconds\n  enableModelVersioning: boolean;\n  enableABTesting: boolean;\n}\n\nexport interface ModelInference {\n  modelId: string;\n  input: any;\n  output: any;\n  confidence: number;\n  uncertainty: number;\n  latency: number;\n  timestamp: string;\n}\n\nexport interface EdgeModel {\n  id: string;\n  version: string;\n  type: 'tensorflow' | 'pytorch' | 'onnx';\n  size: number; // bytes\n  accuracy: number;\n  latency: number; // milliseconds\n  isLoaded: boolean;\n}\n\nclass EdgeAIProcessor {\n  static initialize(arg0: { enableUncertaintyQuantification: boolean; enableRealTimeInference: boolean; targetLatency: number; enableModelVersioning: boolean; enableABTesting: boolean; }) {\n    throw new Error('Method not implemented.');\n  }\n  private config: EdgeAIConfig | null = null;\n  private models: Map<string, EdgeModel> = new Map();\n  private isInitialized = false;\n  private inferenceQueue: any[] = [];\n\n  /**\n   * Initialize the Edge AI Processor\n   */\n  async initialize(config: EdgeAIConfig): Promise<void> {\n    try {\n      console.log('üì± Initializing Edge AI Processor...');\n      \n      this.config = config;\n\n      // Initialize uncertainty quantification\n      if (config.enableUncertaintyQuantification) {\n        await this.initializeUncertaintyQuantification();\n      }\n\n      // Initialize real-time inference\n      if (config.enableRealTimeInference) {\n        await this.initializeRealTimeInference(config.targetLatency);\n      }\n\n      // Initialize model versioning\n      if (config.enableModelVersioning) {\n        await this.initializeModelVersioning();\n      }\n\n      // Initialize A/B testing\n      if (config.enableABTesting) {\n        await this.initializeABTesting();\n      }\n\n      // Load pre-trained models\n      await this.loadPretrainedModels();\n\n      this.isInitialized = true;\n      console.log('‚úÖ Edge AI Processor initialized successfully');\n    } catch (error) {\n      console.error('‚ùå Failed to initialize Edge AI Processor:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Initialize uncertainty quantification\n   */\n  private async initializeUncertaintyQuantification(): Promise<void> {\n    console.log('üéØ Initializing Uncertainty Quantification...');\n    \n    // Initialize Bayesian neural networks or ensemble methods\n    \n    console.log('‚úÖ Uncertainty Quantification initialized');\n  }\n\n  /**\n   * Initialize real-time inference pipeline\n   */\n  private async initializeRealTimeInference(targetLatency: number): Promise<void> {\n    console.log(`‚ö° Initializing Real-time Inference (target: ${targetLatency}ms)...`);\n    \n    // Set up inference pipeline with latency optimization\n    \n    console.log('‚úÖ Real-time Inference initialized');\n  }\n\n  /**\n   * Initialize model versioning system\n   */\n  private async initializeModelVersioning(): Promise<void> {\n    console.log('üì¶ Initializing Model Versioning...');\n    \n    // Set up model version management\n    \n    console.log('‚úÖ Model Versioning initialized');\n  }\n\n  /**\n   * Initialize A/B testing for models\n   */\n  private async initializeABTesting(): Promise<void> {\n    console.log('üß™ Initializing A/B Testing...');\n    \n    // Set up A/B testing framework for model comparison\n    \n    console.log('‚úÖ A/B Testing initialized');\n  }\n\n  /**\n   * Load pre-trained models for edge inference\n   */\n  private async loadPretrainedModels(): Promise<void> {\n    console.log('üîÑ Loading Pre-trained Models...');\n    \n    // Load health prediction models\n    const healthModel: EdgeModel = {\n      id: 'health-risk-predictor',\n      version: '1.0.0',\n      type: 'tensorflow',\n      size: 5242880, // 5MB\n      accuracy: 0.92,\n      latency: 50, // 50ms\n      isLoaded: true\n    };\n\n    const vitalsModel: EdgeModel = {\n      id: 'vitals-analyzer',\n      version: '1.0.0',\n      type: 'tensorflow',\n      size: 2097152, // 2MB\n      accuracy: 0.95,\n      latency: 30, // 30ms\n      isLoaded: true\n    };\n\n    const voiceModel: EdgeModel = {\n      id: 'voice-biomarker',\n      version: '1.0.0',\n      type: 'pytorch',\n      size: 10485760, // 10MB\n      accuracy: 0.88,\n      latency: 100, // 100ms\n      isLoaded: true\n    };\n\n    this.models.set('health-risk', healthModel);\n    this.models.set('vitals', vitalsModel);\n    this.models.set('voice', voiceModel);\n    \n    console.log(`‚úÖ Loaded ${this.models.size} pre-trained models`);\n  }\n\n  /**\n   * Perform real-time inference\n   */\n  async performInference(modelId: string, input: any): Promise<ModelInference> {\n    if (!this.isInitialized) {\n      throw new Error('Edge AI Processor not initialized');\n    }\n\n    const startTime = Date.now();\n    const model = this.models.get(modelId);\n    \n    if (!model) {\n      throw new Error(`Model ${modelId} not found`);\n    }\n\n    // Simulate model inference\n    const output = await this.runModelInference(model, input);\n    const endTime = Date.now();\n    const latency = endTime - startTime;\n\n    // Calculate uncertainty if enabled\n    let uncertainty = 0;\n    if (this.config?.enableUncertaintyQuantification) {\n      uncertainty = await this.calculateUncertainty(model, input, output);\n    }\n\n    const inference: ModelInference = {\n      modelId: model.id,\n      input,\n      output,\n      confidence: output.confidence || 0.9,\n      uncertainty,\n      latency,\n      timestamp: new Date().toISOString()\n    };\n\n    // Log inference for A/B testing if enabled\n    if (this.config?.enableABTesting) {\n      await this.logInferenceForABTesting(inference);\n    }\n\n    return inference;\n  }\n\n  /**\n   * Run model inference\n   */\n  private async runModelInference(model: EdgeModel, input: any): Promise<any> {\n    // Simulate model inference based on model type\n    switch (model.type) {\n      case 'tensorflow':\n        return this.runTensorFlowInference(model, input);\n      case 'pytorch':\n        return this.runPyTorchInference(model, input);\n      case 'onnx':\n        return this.runONNXInference(model, input);\n      default:\n        throw new Error(`Unsupported model type: ${model.type}`);\n    }\n  }\n\n  /**\n   * Run TensorFlow inference\n   */\n  private async runTensorFlowInference(model: EdgeModel, input: any): Promise<any> {\n    // Simulate TensorFlow Lite inference\n    await new Promise(resolve => setTimeout(resolve, model.latency));\n    \n    return {\n      prediction: Math.random(),\n      confidence: 0.85 + Math.random() * 0.15,\n      features: input\n    };\n  }\n\n  /**\n   * Run PyTorch inference\n   */\n  private async runPyTorchInference(model: EdgeModel, input: any): Promise<any> {\n    // Simulate PyTorch Mobile inference\n    await new Promise(resolve => setTimeout(resolve, model.latency));\n    \n    return {\n      prediction: Math.random(),\n      confidence: 0.80 + Math.random() * 0.20,\n      features: input\n    };\n  }\n\n  /**\n   * Run ONNX inference\n   */\n  private async runONNXInference(model: EdgeModel, input: any): Promise<any> {\n    // Simulate ONNX Runtime inference\n    await new Promise(resolve => setTimeout(resolve, model.latency));\n    \n    return {\n      prediction: Math.random(),\n      confidence: 0.88 + Math.random() * 0.12,\n      features: input\n    };\n  }\n\n  /**\n   * Calculate uncertainty for prediction\n   */\n  private async calculateUncertainty(model: EdgeModel, input: any, output: any): Promise<number> {\n    // Implement uncertainty quantification (e.g., Monte Carlo Dropout)\n    return Math.random() * 0.1; // Simulated uncertainty\n  }\n\n  /**\n   * Log inference for A/B testing\n   */\n  private async logInferenceForABTesting(inference: ModelInference): Promise<void> {\n    // Log inference results for model comparison\n    console.log('Logging inference for A/B testing:', inference.modelId);\n  }\n\n  /**\n   * Get model performance metrics\n   */\n  getModelMetrics(modelId: string): EdgeModel | undefined {\n    return this.models.get(modelId);\n  }\n\n  /**\n   * Update model version\n   */\n  async updateModel(modelId: string, newVersion: string): Promise<void> {\n    if (!this.config?.enableModelVersioning) {\n      throw new Error('Model versioning not enabled');\n    }\n\n    const model = this.models.get(modelId);\n    if (model) {\n      model.version = newVersion;\n      console.log(`Updated ${modelId} to version ${newVersion}`);\n    }\n  }\n\n  /**\n   * Check if service is initialized\n   */\n  isServiceInitialized(): boolean {\n    return this.isInitialized;\n  }\n\n  /**\n   * Get loaded models\n   */\n  getLoadedModels(): EdgeModel[] {\n    return Array.from(this.models.values());\n  }\n}\n\nexport { EdgeAIProcessor };\nexport default new EdgeAIProcessor();\n"],"mappings":";;;IAiCMA,eAAe;EAAA,SAAAA,gBAAA;IAAAC,eAAA,OAAAD,eAAA;IAAA,KAIXE,MAAM,GAAwB,IAAI;IAAA,KAClCC,MAAM,GAA2B,IAAIC,GAAG,CAAC,CAAC;IAAA,KAC1CC,aAAa,GAAG,KAAK;IAAA,KACrBC,cAAc,GAAU,EAAE;EAAA;EAAA,OAAAC,YAAA,CAAAP,eAAA;IAAAQ,GAAA;IAAAC,KAAA;MAAA,IAAAC,WAAA,GAAAC,iBAAA,CAKlC,WAAiBT,MAAoB,EAAiB;QACpD,IAAI;UACFU,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAC;UAEnD,IAAI,CAACX,MAAM,GAAGA,MAAM;UAGpB,IAAIA,MAAM,CAACY,+BAA+B,EAAE;YAC1C,MAAM,IAAI,CAACC,mCAAmC,CAAC,CAAC;UAClD;UAGA,IAAIb,MAAM,CAACc,uBAAuB,EAAE;YAClC,MAAM,IAAI,CAACC,2BAA2B,CAACf,MAAM,CAACgB,aAAa,CAAC;UAC9D;UAGA,IAAIhB,MAAM,CAACiB,qBAAqB,EAAE;YAChC,MAAM,IAAI,CAACC,yBAAyB,CAAC,CAAC;UACxC;UAGA,IAAIlB,MAAM,CAACmB,eAAe,EAAE;YAC1B,MAAM,IAAI,CAACC,mBAAmB,CAAC,CAAC;UAClC;UAGA,MAAM,IAAI,CAACC,oBAAoB,CAAC,CAAC;UAEjC,IAAI,CAAClB,aAAa,GAAG,IAAI;UACzBO,OAAO,CAACC,GAAG,CAAC,8CAA8C,CAAC;QAC7D,CAAC,CAAC,OAAOW,KAAK,EAAE;UACdZ,OAAO,CAACY,KAAK,CAAC,2CAA2C,EAAEA,KAAK,CAAC;UACjE,MAAMA,KAAK;QACb;MACF,CAAC;MAAA,SAnCKC,UAAUA,CAAAC,EAAA;QAAA,OAAAhB,WAAA,CAAAiB,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAVH,UAAU;IAAA;EAAA;IAAAjB,GAAA;IAAAC,KAAA;MAAA,IAAAoB,oCAAA,GAAAlB,iBAAA,CAwChB,aAAmE;QACjEC,OAAO,CAACC,GAAG,CAAC,+CAA+C,CAAC;QAI5DD,OAAO,CAACC,GAAG,CAAC,0CAA0C,CAAC;MACzD,CAAC;MAAA,SANaE,mCAAmCA,CAAA;QAAA,OAAAc,oCAAA,CAAAF,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAnCb,mCAAmC;IAAA;EAAA;IAAAP,GAAA;IAAAC,KAAA;MAAA,IAAAqB,4BAAA,GAAAnB,iBAAA,CAWjD,WAA0CO,aAAqB,EAAiB;QAC9EN,OAAO,CAACC,GAAG,CAAC,+CAA+CK,aAAa,QAAQ,CAAC;QAIjFN,OAAO,CAACC,GAAG,CAAC,mCAAmC,CAAC;MAClD,CAAC;MAAA,SANaI,2BAA2BA,CAAAc,GAAA;QAAA,OAAAD,4BAAA,CAAAH,KAAA,OAAAC,SAAA;MAAA;MAAA,OAA3BX,2BAA2B;IAAA;EAAA;IAAAT,GAAA;IAAAC,KAAA;MAAA,IAAAuB,0BAAA,GAAArB,iBAAA,CAWzC,aAAyD;QACvDC,OAAO,CAACC,GAAG,CAAC,qCAAqC,CAAC;QAIlDD,OAAO,CAACC,GAAG,CAAC,gCAAgC,CAAC;MAC/C,CAAC;MAAA,SANaO,yBAAyBA,CAAA;QAAA,OAAAY,0BAAA,CAAAL,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAzBR,yBAAyB;IAAA;EAAA;IAAAZ,GAAA;IAAAC,KAAA;MAAA,IAAAwB,oBAAA,GAAAtB,iBAAA,CAWvC,aAAmD;QACjDC,OAAO,CAACC,GAAG,CAAC,gCAAgC,CAAC;QAI7CD,OAAO,CAACC,GAAG,CAAC,2BAA2B,CAAC;MAC1C,CAAC;MAAA,SANaS,mBAAmBA,CAAA;QAAA,OAAAW,oBAAA,CAAAN,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAnBN,mBAAmB;IAAA;EAAA;IAAAd,GAAA;IAAAC,KAAA;MAAA,IAAAyB,qBAAA,GAAAvB,iBAAA,CAWjC,aAAoD;QAClDC,OAAO,CAACC,GAAG,CAAC,kCAAkC,CAAC;QAG/C,IAAMsB,WAAsB,GAAG;UAC7BC,EAAE,EAAE,uBAAuB;UAC3BC,OAAO,EAAE,OAAO;UAChBC,IAAI,EAAE,YAAY;UAClBC,IAAI,EAAE,OAAO;UACbC,QAAQ,EAAE,IAAI;UACdC,OAAO,EAAE,EAAE;UACXC,QAAQ,EAAE;QACZ,CAAC;QAED,IAAMC,WAAsB,GAAG;UAC7BP,EAAE,EAAE,iBAAiB;UACrBC,OAAO,EAAE,OAAO;UAChBC,IAAI,EAAE,YAAY;UAClBC,IAAI,EAAE,OAAO;UACbC,QAAQ,EAAE,IAAI;UACdC,OAAO,EAAE,EAAE;UACXC,QAAQ,EAAE;QACZ,CAAC;QAED,IAAME,UAAqB,GAAG;UAC5BR,EAAE,EAAE,iBAAiB;UACrBC,OAAO,EAAE,OAAO;UAChBC,IAAI,EAAE,SAAS;UACfC,IAAI,EAAE,QAAQ;UACdC,QAAQ,EAAE,IAAI;UACdC,OAAO,EAAE,GAAG;UACZC,QAAQ,EAAE;QACZ,CAAC;QAED,IAAI,CAACvC,MAAM,CAAC0C,GAAG,CAAC,aAAa,EAAEV,WAAW,CAAC;QAC3C,IAAI,CAAChC,MAAM,CAAC0C,GAAG,CAAC,QAAQ,EAAEF,WAAW,CAAC;QACtC,IAAI,CAACxC,MAAM,CAAC0C,GAAG,CAAC,OAAO,EAAED,UAAU,CAAC;QAEpChC,OAAO,CAACC,GAAG,CAAC,YAAY,IAAI,CAACV,MAAM,CAACoC,IAAI,qBAAqB,CAAC;MAChE,CAAC;MAAA,SAvCahB,oBAAoBA,CAAA;QAAA,OAAAW,qBAAA,CAAAP,KAAA,OAAAC,SAAA;MAAA;MAAA,OAApBL,oBAAoB;IAAA;EAAA;IAAAf,GAAA;IAAAC,KAAA;MAAA,IAAAqC,iBAAA,GAAAnC,iBAAA,CA4ClC,WAAuBoC,OAAe,EAAEC,KAAU,EAA2B;QAAA,IAAAC,YAAA,EAAAC,aAAA;QAC3E,IAAI,CAAC,IAAI,CAAC7C,aAAa,EAAE;UACvB,MAAM,IAAI8C,KAAK,CAAC,mCAAmC,CAAC;QACtD;QAEA,IAAMC,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC;QAC5B,IAAMC,KAAK,GAAG,IAAI,CAACpD,MAAM,CAACqD,GAAG,CAACT,OAAO,CAAC;QAEtC,IAAI,CAACQ,KAAK,EAAE;UACV,MAAM,IAAIJ,KAAK,CAAC,SAASJ,OAAO,YAAY,CAAC;QAC/C;QAGA,IAAMU,MAAM,SAAS,IAAI,CAACC,iBAAiB,CAACH,KAAK,EAAEP,KAAK,CAAC;QACzD,IAAMW,OAAO,GAAGN,IAAI,CAACC,GAAG,CAAC,CAAC;QAC1B,IAAMb,OAAO,GAAGkB,OAAO,GAAGP,SAAS;QAGnC,IAAIQ,WAAW,GAAG,CAAC;QACnB,KAAAX,YAAA,GAAI,IAAI,CAAC/C,MAAM,aAAX+C,YAAA,CAAanC,+BAA+B,EAAE;UAChD8C,WAAW,SAAS,IAAI,CAACC,oBAAoB,CAACN,KAAK,EAAEP,KAAK,EAAES,MAAM,CAAC;QACrE;QAEA,IAAMK,SAAyB,GAAG;UAChCf,OAAO,EAAEQ,KAAK,CAACnB,EAAE;UACjBY,KAAK,EAALA,KAAK;UACLS,MAAM,EAANA,MAAM;UACNM,UAAU,EAAEN,MAAM,CAACM,UAAU,IAAI,GAAG;UACpCH,WAAW,EAAXA,WAAW;UACXnB,OAAO,EAAPA,OAAO;UACPuB,SAAS,EAAE,IAAIX,IAAI,CAAC,CAAC,CAACY,WAAW,CAAC;QACpC,CAAC;QAGD,KAAAf,aAAA,GAAI,IAAI,CAAChD,MAAM,aAAXgD,aAAA,CAAa7B,eAAe,EAAE;UAChC,MAAM,IAAI,CAAC6C,wBAAwB,CAACJ,SAAS,CAAC;QAChD;QAEA,OAAOA,SAAS;MAClB,CAAC;MAAA,SAvCKK,gBAAgBA,CAAAC,GAAA,EAAAC,GAAA;QAAA,OAAAvB,iBAAA,CAAAnB,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAhBuC,gBAAgB;IAAA;EAAA;IAAA3D,GAAA;IAAAC,KAAA;MAAA,IAAA6D,kBAAA,GAAA3D,iBAAA,CA4CtB,WAAgC4C,KAAgB,EAAEP,KAAU,EAAgB;QAE1E,QAAQO,KAAK,CAACjB,IAAI;UAChB,KAAK,YAAY;YACf,OAAO,IAAI,CAACiC,sBAAsB,CAAChB,KAAK,EAAEP,KAAK,CAAC;UAClD,KAAK,SAAS;YACZ,OAAO,IAAI,CAACwB,mBAAmB,CAACjB,KAAK,EAAEP,KAAK,CAAC;UAC/C,KAAK,MAAM;YACT,OAAO,IAAI,CAACyB,gBAAgB,CAAClB,KAAK,EAAEP,KAAK,CAAC;UAC5C;YACE,MAAM,IAAIG,KAAK,CAAC,2BAA2BI,KAAK,CAACjB,IAAI,EAAE,CAAC;QAC5D;MACF,CAAC;MAAA,SAZaoB,iBAAiBA,CAAAgB,GAAA,EAAAC,GAAA;QAAA,OAAAL,kBAAA,CAAA3C,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAjB8B,iBAAiB;IAAA;EAAA;IAAAlD,GAAA;IAAAC,KAAA;MAAA,IAAAmE,uBAAA,GAAAjE,iBAAA,CAiB/B,WAAqC4C,KAAgB,EAAEP,KAAU,EAAgB;QAE/E,MAAM,IAAI6B,OAAO,CAAC,UAAAC,OAAO;UAAA,OAAIC,UAAU,CAACD,OAAO,EAAEvB,KAAK,CAACd,OAAO,CAAC;QAAA,EAAC;QAEhE,OAAO;UACLuC,UAAU,EAAEC,IAAI,CAACC,MAAM,CAAC,CAAC;UACzBnB,UAAU,EAAE,IAAI,GAAGkB,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,IAAI;UACvCC,QAAQ,EAAEnC;QACZ,CAAC;MACH,CAAC;MAAA,SATauB,sBAAsBA,CAAAa,GAAA,EAAAC,GAAA;QAAA,OAAAT,uBAAA,CAAAjD,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAtB2C,sBAAsB;IAAA;EAAA;IAAA/D,GAAA;IAAAC,KAAA;MAAA,IAAA6E,oBAAA,GAAA3E,iBAAA,CAcpC,WAAkC4C,KAAgB,EAAEP,KAAU,EAAgB;QAE5E,MAAM,IAAI6B,OAAO,CAAC,UAAAC,OAAO;UAAA,OAAIC,UAAU,CAACD,OAAO,EAAEvB,KAAK,CAACd,OAAO,CAAC;QAAA,EAAC;QAEhE,OAAO;UACLuC,UAAU,EAAEC,IAAI,CAACC,MAAM,CAAC,CAAC;UACzBnB,UAAU,EAAE,IAAI,GAAGkB,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,IAAI;UACvCC,QAAQ,EAAEnC;QACZ,CAAC;MACH,CAAC;MAAA,SATawB,mBAAmBA,CAAAe,GAAA,EAAAC,GAAA;QAAA,OAAAF,oBAAA,CAAA3D,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAnB4C,mBAAmB;IAAA;EAAA;IAAAhE,GAAA;IAAAC,KAAA;MAAA,IAAAgF,iBAAA,GAAA9E,iBAAA,CAcjC,WAA+B4C,KAAgB,EAAEP,KAAU,EAAgB;QAEzE,MAAM,IAAI6B,OAAO,CAAC,UAAAC,OAAO;UAAA,OAAIC,UAAU,CAACD,OAAO,EAAEvB,KAAK,CAACd,OAAO,CAAC;QAAA,EAAC;QAEhE,OAAO;UACLuC,UAAU,EAAEC,IAAI,CAACC,MAAM,CAAC,CAAC;UACzBnB,UAAU,EAAE,IAAI,GAAGkB,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,IAAI;UACvCC,QAAQ,EAAEnC;QACZ,CAAC;MACH,CAAC;MAAA,SATayB,gBAAgBA,CAAAiB,GAAA,EAAAC,IAAA;QAAA,OAAAF,iBAAA,CAAA9D,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAhB6C,gBAAgB;IAAA;EAAA;IAAAjE,GAAA;IAAAC,KAAA;MAAA,IAAAmF,qBAAA,GAAAjF,iBAAA,CAc9B,WAAmC4C,KAAgB,EAAEP,KAAU,EAAES,MAAW,EAAmB;QAE7F,OAAOwB,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,GAAG;MAC5B,CAAC;MAAA,SAHarB,oBAAoBA,CAAAgC,IAAA,EAAAC,IAAA,EAAAC,IAAA;QAAA,OAAAH,qBAAA,CAAAjE,KAAA,OAAAC,SAAA;MAAA;MAAA,OAApBiC,oBAAoB;IAAA;EAAA;IAAArD,GAAA;IAAAC,KAAA;MAAA,IAAAuF,yBAAA,GAAArF,iBAAA,CAQlC,WAAuCmD,SAAyB,EAAiB;QAE/ElD,OAAO,CAACC,GAAG,CAAC,oCAAoC,EAAEiD,SAAS,CAACf,OAAO,CAAC;MACtE,CAAC;MAAA,SAHamB,wBAAwBA,CAAA+B,IAAA;QAAA,OAAAD,yBAAA,CAAArE,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAxBsC,wBAAwB;IAAA;EAAA;IAAA1D,GAAA;IAAAC,KAAA,EAQtC,SAAAyF,eAAeA,CAACnD,OAAe,EAAyB;MACtD,OAAO,IAAI,CAAC5C,MAAM,CAACqD,GAAG,CAACT,OAAO,CAAC;IACjC;EAAC;IAAAvC,GAAA;IAAAC,KAAA;MAAA,IAAA0F,YAAA,GAAAxF,iBAAA,CAKD,WAAkBoC,OAAe,EAAEqD,UAAkB,EAAiB;QAAA,IAAAC,aAAA;QACpE,IAAI,GAAAA,aAAA,GAAC,IAAI,CAACnG,MAAM,aAAXmG,aAAA,CAAalF,qBAAqB,GAAE;UACvC,MAAM,IAAIgC,KAAK,CAAC,8BAA8B,CAAC;QACjD;QAEA,IAAMI,KAAK,GAAG,IAAI,CAACpD,MAAM,CAACqD,GAAG,CAACT,OAAO,CAAC;QACtC,IAAIQ,KAAK,EAAE;UACTA,KAAK,CAAClB,OAAO,GAAG+D,UAAU;UAC1BxF,OAAO,CAACC,GAAG,CAAC,WAAWkC,OAAO,eAAeqD,UAAU,EAAE,CAAC;QAC5D;MACF,CAAC;MAAA,SAVKE,WAAWA,CAAAC,IAAA,EAAAC,IAAA;QAAA,OAAAL,YAAA,CAAAxE,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAX0E,WAAW;IAAA;EAAA;IAAA9F,GAAA;IAAAC,KAAA,EAejB,SAAAgG,oBAAoBA,CAAA,EAAY;MAC9B,OAAO,IAAI,CAACpG,aAAa;IAC3B;EAAC;IAAAG,GAAA;IAAAC,KAAA,EAKD,SAAAiG,eAAeA,CAAA,EAAgB;MAC7B,OAAOC,KAAK,CAACC,IAAI,CAAC,IAAI,CAACzG,MAAM,CAAC0G,MAAM,CAAC,CAAC,CAAC;IACzC;EAAC;IAAArG,GAAA;IAAAC,KAAA,EAjSD,SAAOgB,UAAUA,CAACqF,IAAsK,EAAE;MACxL,MAAM,IAAI3D,KAAK,CAAC,yBAAyB,CAAC;IAC5C;EAAC;AAAA;AAkSH,SAASnD,eAAe;AACxB,eAAe,IAAIA,eAAe,CAAC,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}